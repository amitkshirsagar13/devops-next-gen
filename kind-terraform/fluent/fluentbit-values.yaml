service:
  prometheus.io/path: "/api/v1/metrics/prometheus"
  prometheus.io/port: "2020"
  prometheus.io/scrape: "true"

ingress:
  enabled: true
  className: nginx
  annotations:
    kubernetes.io/ingress.class: nginx
  hosts:
  - host: fluent-bit.localtest.me

## Prometheus Monitoring
##
serviceMonitor:
  enabled: true
  selector:
    release: kube-prometheus-stack
  namespace: logging
  namespaceSelector:
    ## metric relabel configs to apply to samples before ingestion.
    ##
    metricRelabelings:
    # - sourceLabels: [__name__]
    #   separator: ;
    #   regex: ^fluentd_output_status_buffer_(oldest|newest)_.+
    #   replacement: $1
    #   action: drop
    ## relabel configs to apply to samples after ingestion.
    ##
    relabelings:
    # - sourceLabels: [__meta_kubernetes_pod_node_name]
    #   separator: ;
    #   regex: ^(.*)$
    #   targetLabel: nodename
    #   replacement: $1
    #   action: replace
    ## Additional serviceMonitor config
    ##
    # jobLabel: fluentd
    # scrapeInterval: 30s
    # scrapeTimeout: 5s
    # honorLabels: true



prometheusRule:
  enabled: false
  additionalLabels:
    release: "kube-prometheus-stack"
  namespace: logging
  rules:
  - alert: NoOutputBytesProcessed
    expr: rate(fluentbit_output_proc_bytes_total[5m]) == 0
    annotations:
      message: |
        Fluent Bit instance {{ $labels.instance }}'s output plugin {{ $labels.name }} has not processed any
        bytes for at least 15 minutes.
      summary: No Output Bytes Processed
    for: 15m
    labels:
      severity: critical
  - alert: FluentdDown
    expr: up{job="fluentd"} == 0
    for: 5m
    labels:
      context: fluentd
      severity: warning
    annotations:
      summary: "Fluentd Down"
      description: "{{ $labels.pod }} on {{ $labels.nodename }} is down"
  - alert: FluentdScrapeMissing
    expr: absent(up{job="fluentd"} == 1)
    for: 3m
    labels:
      context: fluentd
      severity: warning
    annotations:
      summary: "Fluentd Scrape Missing"
      description: "Fluentd instance has disappeared from Prometheus target discovery"
  - alert: FluentdCloudWatchLogsNotShipping
    expr: fluentd_output_status_emit_records{plugin_id="ignore_fluent_logs",type="null"} > 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: Fluentd is not shipping logs to CloudWatch
      description: "Fluentd is not sending logs to CloudWatch. Check Fluentd's configuration and logs for errors."

dashboards:
  enabled: "false"
