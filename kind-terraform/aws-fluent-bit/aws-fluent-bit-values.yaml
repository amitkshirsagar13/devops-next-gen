global:
  namespaceOverride: logging

image:
  repository: public.ecr.aws/aws-observability/aws-for-fluent-bit
  tag: 2.28.4
  pullPolicy: IfNotPresent

podSecurityContext: {}
# runAsUser: 1000
# runAsGroup: 1000
# runAsNonRoot: true
# seccompProfile:
#   type: RuntimeDefault
containerSecurityContext: {}
# allowPrivilegeEscalation: false
# capabilities: 
#   drop:
#   - ALL

rbac:
  pspEnabled: false
service:
  ## Allow the service to be exposed for monitoring
  ## https://docs.fluentbit.io/manual/administration/monitoring
  extraService: |
    HTTP_Server  On
    HTTP_Listen  0.0.0.0
    HTTP_PORT    2020
  parsersFiles:
    - /fluent-bit/parsers/parsers.conf
  # extraParsers: |
  #   [PARSER]
  #       Name   logfmt
  #       Format logfmt

input:
  enabled: true
  tag: "kube.*"
  path: "/var/log/containers/*.log"
  db: "/var/log/flb_kube.db"
  parser: docker
  dockerMode: "On"
  memBufLimit: 5MB
  skipLongLines: "On"
  refreshInterval: 10
  # extraInputs: |
  #   ...

# additionalInputs: |
#   [INPUT]
#       Name         winlog
#       Channels     Setup,Windows PowerShell
#       Interval_Sec 1
#       DB           winlog.sqlite

filter:
  enabled: true
  match: "kube.*"
  kubeURL: "https://kubernetes.default.svc.cluster.local:443"
  mergeLog: "On"
  mergeLogKey: "data"
  keepLog: "On"
  k8sLoggingParser: "On"
  k8sLoggingExclude: "On"
  bufferSize: "32k"
# Uncomment the extraFilters to use Kubelet to get the Metadata instead of talking to API server for large clusters
# Check this link for more details https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/ContainerInsights-use-kubelet.html
#  extraFilters: |
#    Kube_Tag_Prefix     application.var.log.containers.
#    Labels              Off
#    Annotations         Off
#    Use_Kubelet         true
#    Kubelet_Port        10250
#    Kube_CA_File        /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
#    Kube_Token_File     /var/run/secrets/kubernetes.io/serviceaccount/token

# additionalFilters: |
#   [FILTER]
#       Name   grep
#       Match  *
#       Exclude log lvl=debug*

cloudWatch:
  enabled: false
  match: "*"
  region: "us-east-1"
  logGroupName: "/aws/eks/fluentbit-cloudwatch/logs"
  logStreamName:
  logStreamPrefix: "fluentbit-"
  logKey:
  logFormat:
  logRetentionDays:
  roleArn:
  autoCreateGroup: true
  endpoint:
  credentialsEndpoint: {}
  # extraOutputs: |
  #   ...

cloudWatchLogs:
  enabled: true
  match: "*"
  region: "us-east-1"
  logGroupName: "/aws/eks/fluentbit-cloudwatch/logs"
  logGroupTemplate: /aws/eks/fluentbit-cloudwatch/workload/$kubernetes['namespace_name']
  logStreamName:
  logStreamPrefix: "fluentbit-"
  logStreamTemplate: $kubernetes['pod_name'].$kubernetes['container_name']
  logKey:
  logFormat:
  roleArn:
  autoCreateGroup: true
  logRetentionDays:
  endpoint:
  metricNamespace:
  metricDimensions:
  stsEndpoint:
  autoRetryRequests:
  externalId:
  # extraOutputs: |
  #  log_format json/emf
  #  worker 1

serviceAccount:
  create: true
  annotations: {}
  name:

resources:
  limits:
    memory: 250Mi
  requests:
    cpu: 50m
    memory: 50Mi

## Assign a PriorityClassName to pods if set
# priorityClassName: system-node-critical

updateStrategy:
  type: RollingUpdate

nodeSelector: {}

tolerations: []

affinity: {}

annotations:
  {}
  # iam.amazonaws.com/role: arn:aws:iam::123456789012:role/role-for-fluent-bit

# Specifies if aws-for-fluent-bit should be started in hostNetwork mode.
#
# This is required if using a custom CNI where the managed control plane nodes are unable to initiate
# network connections to the pods, for example using Calico CNI plugin on EKS. This is not required or
# recommended if using the Amazon VPC CNI plugin.

# Set hostNetwork to true and dnsPolicy to ClusterFirstWithHostNet to use Kubelet to get the Metadata for large clusters
# Check this link for more details https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/ContainerInsights-use-kubelet.html
hostNetwork: false
dnsPolicy: ClusterFirst

env: 
## To add extra environment variables to the pods, add as below
env:
  - name: AWS_REGION
    value: us-east-1
  - name: CLUSTER_NAME
    value: kind-dev
  - name: HOST_NAME
    valueFrom:
      fieldRef:
        fieldPath: spec.nodeName

volumes:
  - name: varlog
    hostPath:
      path: /var/log
  - name: varlibdockercontainers
    hostPath:
      path: /var/lib/docker/containers

volumeMounts:
  - name: varlog
    mountPath: /var/log
  - name: varlibdockercontainers
    mountPath: /var/lib/docker/containers
    readOnly: true

serviceMonitor:
  service:
    type: ClusterIP
    port: 2020
    targetPort: 2020
  # When set true then use a ServiceMonitor to configure scraping
  enabled: true
  # Set the namespace the ServiceMonitor should be deployed
  namespace: monitoring
  # Set how frequently Prometheus should scrape
  # interval: 30s
  # Set path of metrics, e.g /api/v1/metrics/prometheus
  # telemetryPath: /api/v1/metrics/prometheus
  # Set labels for the ServiceMonitor, use this to define your scrape label for Prometheus Operator
  # labels:
  # Set timeout for scrape
  # timeout: 10s
  # Set relabel_configs as per https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config
  # relabelings: []
  # Set of labels to transfer on the Kubernetes Service onto the target.
  # targetLabels: []
  # metricRelabelings: []
