global:
## Override the deployment namespace
#   namespaceOverride:

image:
  repository: ${ECR_IMAGE_REPO}
  tag: ${ECR_IMAGE_TAG}
  pullPolicy: IfNotPresent

resources:
  limits:
    memory: 250Mi
  requests:
    cpu: 50m
    memory: 50Mi
tolerations: []

# annotations:
# iam.amazonaws.com/role: arn:aws:iam::123456789012:role/role-for-fluent-bit

rbac:
  # rbac.pspEnabled, if `true` a restricted pod security policy is created and used
  pspEnabled: false

input:
  enabled: true
  tag: "kubernetes.*"
  path: "/var/log/containers/*.log"
  # excludePath:
  #   - "/var/log/containers/cloudwatch-agent*"
  #   - "/var/log/containers/fluentd*"
  #   - "/var/log/containers/fluentbit*"
  db: "/var/log/flb_kube.db"
  parser: docker
  dockerMode: "On"
  memBufLimit: 10MB
  skipLongLines: "Off"
  refreshInterval: 10
  readFromHead: true
  # extraInputs: |
  #   time_format %Y-%m-%dT%H:%M:%S.%NZ
  #   @type json
  #   ...

filter:
  enabled: false
  match: "kube.*"
  kubeURL: "https://kubernetes.default.svc.cluster.local:443"
  mergeLog: "On"
  mergeLogKey: "data"
  keepLog: "On"
  k8sLoggingParser: "On"
  k8sLoggingExclude: "On"
  bufferSize: "32k"
# Uncomment the extraFilters to use Kubelet to get the Metadata instead of talking to API server for large clusters
# Check this link for more details https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/ContainerInsights-use-kubelet.html
#  extraFilters: |
#    Kube_Tag_Prefix     application.var.log.containers.
#    Labels              Off
#    Annotations         Off
#    Use_Kubelet         true
#    Kubelet_Port        10250
#    Kube_CA_File        /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
#    Kube_Token_File     /var/run/secrets/kubernetes.io/serviceaccount/token

additionalFilters: |
  [FILTER]
      Name record_modifier
      Match *
      Record clustername ${CLUSTER_NAME}
      Record region ${REGION}
      Record team ${TEAM}
      Record stage ${LEVEL}
      Remove_key $.kubernetes.pod_id, , , 
      Remove_key $.kubernetes.master_url
      Remove_key $.kubernetes.container_image_id
      Remove_key $.kubernetes.namespace_id
  [FILTER]
    Name              kubernetes
    Match             kube.*
    Kube_URL          https://kubernetes.default.svc.cluster.local:443
  [FILTER]
    Name parser
    Match *
    Key_Name log
    Reserve_Data true
    Reserve_Time true
    Parser json

# cloudWatch:
#   enabled: true
#   match: "*"
#   region: us-east-1
#   logGroupName: "/aws/eks/fluentbit-cloudwatch/logs"
#   logStreamName:
#   logStreamPrefix: "fluentbit-"
#   logKey:
#   logFormat:
#   logRetentionDays:
#   roleArn:
#   autoCreateGroup: true
#   endpoint:
#   credentialsEndpoint: {}
# extraOutputs: |
#   ...

cloudWatchLogs:
  enabled: true
  match: "*"
  region: ${REGION}
  logGroupName: fluentbit-${CLUSTER_NAME}-logs
  logGroupTemplate: fluentbit-${CLUSTER_NAME}-logs/workload/$kubernetes['namespace_name']
  logStreamName:
  logStreamPrefix: "fluentbit-"
  # logStreamTemplate: $kubernetes['pod_name'].$kubernetes['container_name']
  logKey:
  logFormat:
  roleArn:
  autoCreateGroup: true
  logRetentionDays:
  endpoint:
  metricNamespace:
  metricDimensions:
  stsEndpoint:
  autoRetryRequests:
  externalId:
  # extraOutputs: |
  #  log_format json/emf
  #  worker 1

## Assign a PriorityClassName to pods if set
# priorityClassName: system-node-critical

updateStrategy:
  type: RollingUpdate

# Specifies if aws-for-fluent-bit should be started in hostNetwork mode.
#
# This is required if using a custom CNI where the managed control plane nodes are unable to initiate
# network connections to the pods, for example using Calico CNI plugin on EKS. This is not required or
# recommended if using the Amazon VPC CNI plugin.

# Set hostNetwork to true and dnsPolicy to ClusterFirstWithHostNet to use Kubelet to get the Metadata for large clusters
# Check this link for more details https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/ContainerInsights-use-kubelet.html
hostNetwork: false
dnsPolicy: ClusterFirst

## To add extra environment variables to the pods, add as below
env:
  - name: AWS_REGION
    value: ${REGION}
  - name: CLUSTER_NAME
    value: ${CLUSTER_NAME}
  - name: HOST_NAME
    valueFrom:
      fieldRef:
        fieldPath: spec.nodeName

volumes:
  - name: varlog
    hostPath:
      path: /var/log
  - name: varlibdockercontainers
    hostPath:
      path: /var/lib/docker/containers

volumeMounts:
  - name: varlog
    mountPath: /var/log
  - name: varlibdockercontainers
    mountPath: /var/lib/docker/containers
    readOnly: true

serviceMonitor:
  service:
    type: ClusterIP
    port: 2020
    targetPort: 2020
  # When set true then use a ServiceMonitor to configure scraping
  enabled: true
  # Set the namespace the ServiceMonitor should be deployed
  namespace: fluentbit
  # Set how frequently Prometheus should scrape
  # interval: 30s
  # Set path of metrics, e.g /api/v1/metrics/prometheus
  telemetryPath: /api/v1/metrics/prometheus
  # Set labels for the ServiceMonitor, use this to define your scrape label for Prometheus Operator
  # labels:
  # Set timeout for scrape
  # timeout: 10s
  # Set relabel_configs as per https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config
  # relabelings: []
  # Set of labels to transfer on the Kubernetes Service onto the target.
  # targetLabels: []
  # metricRelabelings: []


